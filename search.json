[
  {
    "objectID": "analysis/native-american-markers.html",
    "href": "analysis/native-american-markers.html",
    "title": "Native American Markers",
    "section": "",
    "text": "library(tidyverse)\nlibrary(mapview)\nlibrary(here)\nlibrary(htmltools)\nlibrary(purrr)\nlibrary(jsonlite)\nlibrary(configr)\nlibrary(RcppTOML)\n\n\nsource(here(\"analysis/_functions.R\"))\n\nThese categories:\n\nnative_american_topic_phrases = c(\"indian\", \"native americans\", \"settlers\")\n\nnative_categories = marker_categories_df  %&gt;% \n    filter(str_detect(category, paste(\"\\\\b\", native_american_topic_phrases, \"\\\\b\", sep = \"\", collapse = \"|\")))\n\nunique(native_categories$category)\n\n[1] \"native americans\"       \"settlements & settlers\" \"war, french and indian\"\n[4] \"wars, us indian\"       \n\n\nThese series:\n\nnative_american_topic_phrases = c(\"indian\", \"native americans\", \"settlers\")\n\nnative_series = marker_series_df  %&gt;% \n    filter(str_detect(name, paste(\"\\\\b\", native_american_topic_phrases, \"\\\\b\", sep = \"\", collapse = \"|\")) | str_detect(optional_title, paste(\"\\\\b\", native_american_topic_phrases, \"\\\\b\", sep = \"\", collapse = \"|\"))  )\n\nnative_series  %&gt;% \n    distinct(name, optional_title)\n\n                                        name       optional_title\n1        great indian warrior / trading path     roads and trails\n2             indian wars battlefield trails    wars, u.s. indian\n3                             black hawk war    wars, u.s. indian\n4                  potawatomi trail of death    wars, u.s. indian\n5                        the nez perce trail    wars, u.s. indian\n6 mary jemison - white woman of the genessee war, french & indian\n\n\nCreate two different indigenous marker datasets, a data frame of all Native American markers ever put up and ones that are currently up.\n\nall_native_american_marker_id = tibble(marker_id = c(native_series$marker_id,native_categories$marker_id ))\n\nnative_american_markers_all_df = all_valid_markers_df  %&gt;% \n    filter(marker_id %in% all_native_american_marker_id$marker_id ) \n\nnative_american_markers_up_df = all_valid_markers_up_df  %&gt;% \n    filter(marker_id %in% all_native_american_marker_id$marker_id )\n\n\nSentence\n\n+up_first_sunday_podcast: We found more than 15,000 markers across the country that mentioned Native Americans,\n\n\n+digital: Across the country, more than 15,000 markers mention Native Americans.\nAll of the series and categories are specifically about Native Americans except for the category \"settlements & settlers\". Therefore to get a list of all markers that mention Native Americans I will:\n\nAutomatically include any marker taged in the series or category mentioned above that is not a \"settlements & settlers\"\nFor the \"settlements & settlers\" markers, I will search for phrases related to Native Americans and only include those in the total\n\n\nsettlements_settlers_marker_id = native_categories  %&gt;% \n    filter(category_id == 12)\n\n# Search just for settlement markers that arent part of another native american category\nsettlements_to_search = all_native_american_marker_id  %&gt;% \n    summarize(n = n(), .by = marker_id) %&gt;% \n    filter(marker_id %in% settlements_settlers_marker_id$marker_id & n == 1)\n\n# Markers belong to just the native american categories we defined (exlcuding just settlements)\n\nall_native_excluding_solo_settlemnts = all_native_american_marker_id  %&gt;% \n    summarize(n = n(), .by = marker_id) %&gt;% \n    filter(!(marker_id %in% settlements_settlers_marker_id$marker_id & n == 1))\n\n\n# Search the just settlement markers for native american terms (including racists terms)\nsolo_settlements_about_natives = native_american_markers_up_df   %&gt;% \n    filter(marker_id %in% settlements_to_search$marker_id ) %&gt;% \n    filter(str_detect(text,paste(\"\\\\b\", c(\"indian\", \"indians\", \"red skin\", \"red skins\", \"redskin\", \"redskins\", \"native american\", \"native americans\"), \"\\\\b\", sep = \"\", collapse = \"|\")) )\n\n\n# The total number is then the two data frames rows added\n\ntotal_indian_markers = tibble(marker_id = c(all_native_excluding_solo_settlemnts$marker_id,solo_settlements_about_natives$marker_id ))\n\nnative_american_markers_up_df = native_american_markers_up_df  %&gt;% \n    filter(marker_id %in% total_indian_markers$marker_id)\n\n\nnrow(native_american_markers_up_df)\n\n[1] 15200\n\n\n\n\n\nSentence:\n\n+up_first_sunday_podcast: Hundreds of markers still call Native Americans savages, hostile, or use racial slurs.\n\n\n+digital: From the Atlantic through the Plains, more than 270 markers describe Native Americans as “savage,” “hostile” or “semi-civilized,” or they use racial slurs.\n\n\n+marking_the_frontier_radio: NPR found hundreds of markers that still call Native Americans savage, hostile, or use racial slurs.\n\npattern = c(\"mound builders\",\n\"stone age\",\n\"hostile indian\",\n\"hostile tribe\",\n\"hostiles\",\n\"savages\",\n\"indian savages\",\n\"savage boy\",\n\"savage indian\",\n\"civilized tribes\",\n\"mound-building\",\n\"vengeful\",\n\"semi-civilized\",\n\"\\\\bred men\\\\b\",\n\"\\\\bred man\\\\b\",\n\"\\\\bredmen\\\\b\",\n\"\\\\bredman\\\\b\",\n\"red paint people\",\n\"half-breed\",\n\"civilized indian\",\n\"indian brave\",\n\"redskin\",\n\"hostile red indian\")\n\n# Gathered for handcheck\noffensive_native_markers_df = native_american_markers_up_df  %&gt;% \n    filter(str_detect(text, paste(pattern, collapse = \"|\")) | str_detect(title, paste(pattern, collapse = \"|\")) ) %&gt;% \n     mutate(matched_words_text = sapply(str_extract_all(text, paste(pattern, collapse = \"|\")), paste, collapse = \", \"), .before = url)  %&gt;% \n     mutate(matched_words_title = sapply(str_extract_all(title, paste(pattern, collapse = \"|\")), paste, collapse = \", \"), .before = url) \n\n\n\n\n# Read in handchecked data\noffensive_american_indian_handchecked_df = read.csv(here(\"data/handmade/offensive_native_markers - offensive_native_markers.csv\"))\n\n\noffensive_american_indian_handchecked_df  %&gt;% \n    filter(yes_no_maybe == \"yes\") %&gt;% \n    summarize(n = n(), .by = yes_no_maybe)\n\n  yes_no_maybe   n\n1          yes 274\n\ncount(offensive_american_indian_handchecked_df, yes_no_maybe) %&gt;% \n    cat_table(\"Offensive Native American Markers\")\n\n\n\n\nOffensive Native American Markers\n\n\n\n\n\n\n\n\n\n\nSentence:\n\n+up_first_sunday_podcast: We found at least two hundred that tell an eerily similar story: Innocent white settlers were minding their own business when one day for no reason Native Americans appeared and killed them in cold blood.\n\n\n+up_first_sunday_podcast: We are, we’re heading to the Midwest, to the frontier where we found markers that really glorify white settlers, but vilify Native Americans.\n\n\n+digital: At least 200 markers tell an eerily similar American tale: Native Americans attacked innocent white settlers for no reason.\n\n\n+marking_the_frontier_radio: More than 200 tell an eerily similar story: Native Americans killed innocent white settlers in cold blood.\nUsed regex patterns to search for iterations of common phrases used when talking about settlers being killed by Native Americans, and then handchecked them.\n\n# Define regex pattern for identifying instances of killings by Indians\nindian_pattern &lt;- \"(?i)\\\\b(?:killed|attacked|murdered|massacre(?:d)?|slain|carried away)\\\\b(?:\\\\s+\\\\w+)?\\\\s+(?:by\\\\s+the\\\\s+)?(?:\\\\w+\\\\s+)*Indians?\"\n\n\nkilled_by_indians_df = native_american_markers_up_df  %&gt;% \n    filter(grepl(indian_pattern, text, ignore.case = TRUE, perl = TRUE) | str_detect(title, \"massacre\")) %&gt;% \n    mutate(mentions_settlers = str_detect(text, \"settler|pioneer|family|families|child|children|father|husband|wife|wives|brother\"), .before = url) %&gt;% \n    mutate(version = \"1\") %&gt;% \n    select(marker_id, url, mentions_settlers, version)\n\n# Previous classification\nmassacre_indian_settler_df = read_csv(here(\"data/handmade/killed_by_indians_check1.csv\")) %&gt;% \n    mutate(version = \"2\") %&gt;% \n    full_join(killed_by_indians_df, join_by(marker_id))\n\n\n# write_csv(massacre_indian_settler_df, here(\"data/processed/native_massacre_final.csv\"))\n\n# Read in handchecked data\n\nkilled_by_indians_checked_df = read_csv(here(\"data/handmade/killed_by_indians_check2.csv\")) %&gt;% \n    filter(killed_by_indians == \"yes\")\n\n\nkilled_by_indians_checked_df  %&gt;% \n    count(killed_by_indians) %&gt;% \n    cat_table(\"Markers that mention settlers being killed by Native Americans\")\n\n\n\n\nMarkers that mention settlers being killed by Native Americans",
    "crumbs": [
      "Analysis",
      "Native American Markers"
    ]
  },
  {
    "objectID": "analysis/organizations.html",
    "href": "analysis/organizations.html",
    "title": "Number of Organizations",
    "section": "",
    "text": "Sentence:\n\n+up_first_sunday: And while the markers often look official, the reality is that anyone can put up a marker - more than 35,000 different groups, historical associations, cities, towns, states, individuals have.\n\n\n+digital: more than 35,000 different groups, societies, organizations, towns, governments and individuals have [put up markers].\n\n\n+marking_hate_watc: More than 35,000 different groups, historical societies, towns, individuals - all kinds of people - have put up markers.\n\n\n+two_way_atc: all kinds of people have — more than 35,000 different groups, and individuals, and towns and societies, organizations - have.\nThe number we report is a minimum number of groups that have put up markers.\nSo first we start off with the organization column and find the number of unique organizations.\n\nlibrary(tidyverse)\nlibrary(here)\nlibrary(jsonlite)\nlibrary(here)\nlibrary(gt)\nlibrary(reticulate)\nlibrary(configr)\nlibrary(RcppTOML)\n\nsource(here(\"analysis/_functions.R\"))\n\n\nall_orgs = all_valid_markers_df  %&gt;% \n    summarize(n = n(), .by = X_organization_original) %&gt;% \n    arrange(desc(n))\n\nWe can see that just by getting unique organizations we arrive at 49,196 organizations.\n\ncat_table(all_orgs, \"Unique organizations\")\n\n\n\n\nUnique organizations\n\n\n\n\n\n\n\nLooking through these, we have a few problems.\n\nMany markers are put up by multiple groups, there is no standard way of separating groups.\n\nExamples below include semi-colons, commas, and dots to separate groups:\n\nMontana Historical Society; Department of the Interior, National Register of Historic Places\nThe Daughters of The American Revolution (DAR) and The State of Texas\nNational Park Service • City of Cave Spring • Trail of Tears Association\n\n\nSome group names have chapters or abbreviations inserted in them\n\nExamples include:\n\nGeneral Robert A. Toombs, Camp 932, SCV, Chapter 1329, UDC\n\nSCV stands for Sons of Confederate Veterans and UDC stands for United Daughters of the Confederacy. Each of the groups has a chapter included with them\n\n\n\n\nTo solve this, I used a local large language model called llama2 to separate each row into a single organization:\nThe code looks like this:\n\nfrom openai import OpenAI\nfrom pydantic import BaseModel, ValidationError, Field\nfrom typing import List\nimport instructor\nimport pandas as pd\nfrom tqdm import tqdm\nfrom pathlib import Path\nimport json\n\n\norgs_df =pd.read_csv(\"/Users/nick/Documents/projects/GitHub/historical-markers/data/processed/all_orgs.csv\")\n\ndata = orgs_df[\"X_organization_original\"].tolist()[1:]\n\n\ndef _save_to_jsonl(file_name, directory, data_dict):\n    \"\"\"\n    Appends a dictionary to a JSONL file in the specified directory.\n    If the file does not exist, it creates the file.\n\n    Args:\n    file_name (str): The name of the file.\n    directory (str): The directory where the file is located or should be created.\n    data_dict (dict): The dictionary to append.\n    \"\"\"\n\n    # Create a Path object for the directory and ensure it exists\n    dir_path = Path(directory)\n    dir_path.mkdir(parents=True, exist_ok=True)\n\n    # Create the full file path\n    file_path = dir_path / file_name\n\n    # Append to the file or create a new one if it doesn't exist\n    with file_path.open('a') as file:\n        json_line = json.dumps(data_dict)\n        file.write(json_line + '\\n')\n\n\nclass Organization(BaseModel):\n    organizations: List[str] = Field(..., description=\"A list of organizations from a sentence\")\n\n\n# enables `response_model` in create call\nclient = instructor.patch(\n    OpenAI(\n        base_url=\"http://localhost:11434/v1\",\n        api_key=\"ollama\",  # required, but unused\n    ),\n    mode=instructor.Mode.JSON,\n)\n\n\nmodel_name = \"llama2\"\n\nresp = client.chat.completions.create(\n        model=model_name,\n        messages=[\n            {\n                \"role\": \"user\",\n                \"content\": f\"Identify the organizations listed in this sentence and output as a json list: mcdonalds; papa johns and wendy's\",\n            }\n        ],\n        response_model=Organization)\n\nresponse_json = resp.model_dump(mode = \"json\")\n\nprint(response_json)\n\n\nmodel_name = \"llama2\"\n\nfor org in tqdm(data):\n    try:\n        resp = client.chat.completions.create(\n        model=model_name,\n        messages=[\n            {\n                \"role\": \"user\",\n                \"content\": f\"Identify the organizations listed in this sentence and output as a json list: {org} \",\n            }\n        ],\n        response_model=Organization)\n\n        response_json = resp.model_dump(mode = \"json\")\n        response_json[\"original\"] = org\n        response_json[\"model\"] = model_name\n        _save_to_jsonl(\"org_separated.jsonl\", \"../data/processed/local-llm/org/\", response_json)\n\n    except ValidationError as exc:\n        error = repr(exc.errors()[0]['type'])\n        response_json = {}\n        response_json[\"error\"] = error\n        response_json[\"original\"] = org\n        response_json[\"model\"] = model_name\n        _save_to_jsonl(\"org_separated_error.jsonl\", \"../data/processed/local-llm/org/\", response_json)\n\n\nai_sep = stream_in(file(here(\"data/processed/local-llm/org/org_separated.jsonl\")))\n\n\n Found 500 records...\n Found 1000 records...\n Found 1500 records...\n Found 2000 records...\n Found 2500 records...\n Found 3000 records...\n Found 3500 records...\n Found 4000 records...\n Found 4500 records...\n Found 5000 records...\n Found 5500 records...\n Found 6000 records...\n Found 6500 records...\n Found 7000 records...\n Found 7500 records...\n Found 8000 records...\n Found 8500 records...\n Found 9000 records...\n Found 9500 records...\n Found 10000 records...\n Found 10500 records...\n Found 11000 records...\n Found 11500 records...\n Found 12000 records...\n Found 12500 records...\n Found 13000 records...\n Found 13500 records...\n Found 14000 records...\n Found 14500 records...\n Found 15000 records...\n Found 15500 records...\n Found 16000 records...\n Found 16500 records...\n Found 17000 records...\n Found 17500 records...\n Found 18000 records...\n Found 18500 records...\n Found 19000 records...\n Found 19500 records...\n Found 20000 records...\n Found 20500 records...\n Found 21000 records...\n Found 21500 records...\n Found 22000 records...\n Found 22500 records...\n Found 23000 records...\n Found 23500 records...\n Found 24000 records...\n Found 24500 records...\n Found 25000 records...\n Found 25500 records...\n Found 26000 records...\n Found 26500 records...\n Found 27000 records...\n Found 27500 records...\n Found 28000 records...\n Found 28500 records...\n Found 29000 records...\n Found 29500 records...\n Found 30000 records...\n Found 30500 records...\n Found 31000 records...\n Found 31500 records...\n Found 32000 records...\n Found 32500 records...\n Found 33000 records...\n Found 33500 records...\n Found 34000 records...\n Found 34500 records...\n Found 35000 records...\n Found 35500 records...\n Found 36000 records...\n Found 36500 records...\n Found 37000 records...\n Found 37500 records...\n Found 38000 records...\n Found 38500 records...\n Found 39000 records...\n Found 39500 records...\n Found 40000 records...\n Found 40500 records...\n Found 41000 records...\n Found 41500 records...\n Found 42000 records...\n Found 42500 records...\n Found 43000 records...\n Found 43500 records...\n Found 44000 records...\n Found 44500 records...\n Found 45000 records...\n Found 45500 records...\n Found 46000 records...\n Found 46500 records...\n Found 46791 records...\n Imported 46791 records. Simplifying...\n\nlines &lt;- readLines(here(\"data/processed/local-llm/org/org_separated.jsonl\"))\njson_list &lt;- lapply(lines, jsonlite::fromJSON)\n\nai_org_raw_df = tibble(data = json_list) %&gt;% \n    unnest_wider(data) %&gt;% \n    unnest_wider(organizations, names_sep = \"_\")\n\n\nai_org_df =ai_org_raw_df  %&gt;% \n    filter(!original %in% c(\": On base of the marker, both front and back, is a list of donors and sponsors.\")) %&gt;% \n    select(-model, -original) %&gt;% \n    pivot_longer(cols = everything(), names_to = \"org_placement\", values_to = \"organization\" ) %&gt;% \n    filter(!is.na(organization)) %&gt;% \n    summarize(n = n(), .by = organization) %&gt;% \n    arrange(desc(n))\n\n# write.csv(ai_org_df, here(\"data/processed/ai_org.csv\"))\n\nAfter separating each row into individual organizations and getting the unique categories we increase our count to 54,200 organizations.\nThe next step is to handle misspellings, different spelling or names for the same organization, and acronyms. I brought the data into OpenRefine and used their clustering algorithms. When I came across chapters I would research and fill in the actual national name when I could.\n\nopen_refine_clustered_raw_df = read_csv(here(\"data/processed/ai-org-csv-openrefine.csv\"))\n\nopen_refine_clustered_df = open_refine_clustered_raw_df %&gt;% \n    summarize(n = n(), .by = organization_cluster)\n\nAfter OpenRefine, I arrived at 49,735 organizations.\nHowever, there are a few caveats to the pipeline:\n\nI wasn’t able to fill in the national group for every chapter\nThe separating of the groups was not perfect\nThe clustering of the groups is not perfect\n\nTherefore I did the following:\n\nremoved any organization that had the words post, chapter, chapters, unit, units, camp, camps, or no. in their name. The assumption here is that we would have gotten their national group in another marker (and even if we didn’t we are looking for a conservative number to report)\nremoved any organization that was just a date (a date might have become an organization name in the separating phase)\nremoved any group that was just one word (a lot of words got separated incorrectly from the main group name so therefore wanting to arrive at a conservative estimate)\n\n\norganization_cleaning = open_refine_clustered_df %&gt;%\n    mutate(remove = case_when(\n        str_detect(organization_cluster, \" post| chapter| chapters| units| units| camp| camps| unit| no.\") ~ 1,\n        str_detect(organization_cluster, \"(january|february|march|april|may|june|july|august|september|october|november|december)\\\\s[1-31]{1,2},\\\\s[0-9]{4}\") ~ 1,\n        str_detect(organization_cluster, \"(january|february|march|april|may|june|july|august|september|october|november|december)\\\\s[1-31]{1,2}\") ~ 1,\n        str_detect(organization_cluster, \"erected\") ~ 1,\n        str_count(organization_cluster, \"\\\\S+\") == 1 ~ 1,\n        TRUE ~ 0\n\n    )) \n\norgs_to_remove = organization_cleaning  %&gt;% \n        filter(remove == 1)  %&gt;% \n        select(organization_cluster)\n\nDoing so removed 7,808 organizations.\n\ncat_table(orgs_to_remove, \"Organizations Removed\")\n\n\n\n\nOrganizations Removed\n\n\n\n\n\n\n\n\nfinal_orgs =  organization_cleaning  %&gt;% \n        filter(remove == 0)  %&gt;% \n        select(organization_cluster) %&gt;% \n        arrange(organization_cluster)\n\n# write.csv(final_orgs, here(\"data/processed/final_orgs_parsed.csv\"))\n\nI brought this cleaned list back into OpenRefine, did a bit more clustering, and then manually clustered groups that OpenRefine was not getting.\n\norg_phrases = c(\"post\", \"chapter\", \"chapters\", \"unit\", \"units\",\"camp\", \"camps\", \"camp\", \"no.\", \"troop\")\n\nfinal_orgs_2 = read.csv(here(\"data/processed/final-orgs-parsed-2.csv\"))\n\nfinal = final_orgs_2  %&gt;%   \n    summarize(n = n(), .by = organization_cluster_2) %&gt;% \n    mutate(organization = gsub(\"[^[:alnum:] ]\", \"\", organization_cluster_2)) %&gt;% \n    mutate(final = case_when(\n        str_detect(organization_cluster_2, \"lion club|lions club|lion's club\") ~ \"lions club\",\n        str_detect(organization_cluster_2, \"society of colonial dames\") ~ \"society of colonial dames\",\n        str_detect(organization_cluster_2, \"rotary\") ~ \"rotary club\",\n        str_detect(organization_cluster_2, \"daughters of the american colonists\") ~ \"daughters of the american colonists\",\n        str_detect(organization_cluster_2, \"sons of confederate veterans|sons of the confederate veterans\") ~ \"sons of confederate veterans\",\n        str_detect(organization_cluster_2, \"ladies memorial association\") ~ \"ladies memorial association\",\n        str_detect(organization_cluster_2, \"daughters of union veterans\") ~ \"daughters of union veterans\",\n        str_detect(organization_cluster_2, \"sons of union veterans\") ~ \"sons of union veterans\",\n        str_detect(organization_cluster_2, \"e clampus|e clampus virtus\") ~ \"e clampus vitus\", \n        str_detect(organization_cluster_2, \"native sons\") ~ \"native sons of the golden west\",\n        str_detect(organization_cluster_2, \"pomeroy\") ~ \"william g pomeroy\",\n        str_detect(organization_cluster_2, \"boy scout\") ~ \"boy scout\",\n        TRUE ~ organization_cluster_2)) %&gt;% \n        summarize(n = n(), .by = final) %&gt;% \n         mutate(start = case_when(\n    str_detect(str_sub(final, 1, 1), \"^[a-zA-Z]\") ~ str_sub(final, 1, 1), # Checks if the first character is a letter\n    str_detect(str_sub(final, 1, 1), \"^[0-9]\") ~ \"number\", # Checks if the first character is a number\n    TRUE ~ \"symbol\" # If the first character is neither letter nor number, it is considered a symbol\n  )) %&gt;%\n    filter(!str_detect(final, paste(\"\\\\b\", org_phrases, \"\\\\b\", sep = \"\", collapse = \"|\"))) %&gt;% \n    arrange(final) \n\nfinal_2dot5 = final\n\n#write_csv(final_2dot5, here(\"data/processed/final_2dot5.csv\"))\n\nfinal_2dot5  %&gt;% \n    mutate(start = case_when(\n    str_detect(str_sub(final, 1, 1), \"^[a-zA-Z]\") ~ str_sub(final, 1, 1), # Checks if the first character is a letter\n    str_detect(str_sub(final, 1, 1), \"^[0-9]\") ~ \"number\", # Checks if the first character is a number\n    TRUE ~ \"symbol\" # If the first character is neither letter nor number, it is considered a symbol\n  )) %&gt;% \n  filter(start == \"a\") %&gt;% \n  write_csv(here(\"data/processed/a.csv\"))\n\nChecking by hand revealed a few more ways to handle any duplicates programmatically. This included removing the following from the start of a string: - the - city of - village of - borough of\nand also replace “&” for “and”, removing non-alpha-numeric characters, and removing “inc”.\nAfter doing this I regrouped the organizations.\n\nfinal_hand_checked_raw_df = read_csv(here(\"data/handmade/final orgs hand checked - Sheet2.csv\"))\n\nfinal_hand_checked_df = final_hand_checked_raw_df  %&gt;% \n    mutate(remove= as.character(remove)) %&gt;% \n    filter(is.na(remove)) %&gt;% \n    mutate(final = str_squish(final)) %&gt;% \n    mutate(final = str_squish(str_remove_all(final, \"^the\"))) %&gt;% \n    mutate(final = str_squish(str_remove_all(final, \"^city of\"))) %&gt;% \n    mutate(final = str_squish(str_remove_all(final, \"^village of\"))) %&gt;% \n     mutate(final = str_squish(str_remove_all(final, \"^borough of\"))) %&gt;% \n    mutate(final = str_squish(str_replace_all(final, \"&\", \"and\"))) %&gt;% \n    mutate(final = str_replace_all(final, \"[^a-zA-Z0-9 ]\", \"\")) %&gt;% \n    mutate(final = str_replace_all(final, \"\\\\binc\\\\b\", \"\")) %&gt;% \n    mutate(final = str_squish(final)) %&gt;% \n    summarize(n = n(), .by = final) %&gt;% \n    arrange(desc(n))\n\nAt the end of this methodology we are left with 37,601\nIt is possible that organizations changed names over the years, therefore I rounded down to 35,000 to account for that.",
    "crumbs": [
      "Analysis",
      "Number of Organizations"
    ]
  },
  {
    "objectID": "analysis/overview.html",
    "href": "analysis/overview.html",
    "title": "Overview",
    "section": "",
    "text": "library(tidyverse)\nlibrary(here)\nsource(here(\"analysis/_functions.R\"))\n\n\nSentence:\n\n+up_first_sunday_podcast: There are more than 180,000 of these “historical markers” – telling the country’s story\n\n\n+digital: With more than 180,000 of them scattered across the U.S.\n\n\n+marking_hate_watc_radio: There are 180,000 historical markers are all over this country telling America’s story.\n\n\n+marking_the_frontier_radio: There are more than 180,000 of them\n\n\n+marking_a_murder_digital: And it’s easy to see why: With more than 180,000 of them, no one has any idea what they all say.\n\n\n+two_way_atc: Alright so more than 180,000 markers -\n\nformat(nrow(all_valid_markers_up_df), big.mark = \",\")\n\n[1] \"188,971\"\n\n\n\n\n\nSentence:\n\n+up_first_sunday_podcast: Because the thing about this marker and thousands of others across this country, is that they are owned by private groups.\n\n\n+digital: Because like thousands of markers nationwide, it was put up by a private group\n\n\n+marking_hate_watc_radio: Because like thousands of markers across the country it’s owned by a private group\nThese are 990’sfrom four private groups:\n\nE Clampus Vitus: https://projects.propublica.org/nonprofits/organizations/953389522\nNative Daughters Of The Golden West: https://projects.propublica.org/nonprofits/organizations/943011278\nUnited Daughters of the Confederacy: https://projects.propublica.org/nonprofits/organizations/540631483\nSons of Confederate Veterans: https://projects.propublica.org/nonprofits/organizations/581329949\n\nSearching for their markers and adding them up leads to:\n\ne_clampus_vitus_df = all_valid_markers_up_df %&gt;% \n  filter(str_detect(organization, \"e clampus\"))\n\nunited_sons_daughters_golden_west_df = all_valid_markers_up_df %&gt;% \n  filter(str_detect(organization, \"native daughters of the golden west|native sons of the golden west\"))\n\nudc_scv_df = read.csv(here(\"data/processed/civil_war_heritage_group_markers_df.csv\")) %&gt;% \n  filter(str_detect(matched_groups, \"sons of confederate veterans|united daughters of the confederacy\"))\n\nprivate_group_example = bind_rows(e_clampus_vitus_df ,united_sons_daughters_golden_west_df, udc_scv_df ) %&gt;% distinct(marker_id, .keep_all = TRUE)\n\nformat(nrow(private_group_example), big.mark= \",\")\n\n[1] \"3,125\"\n\n\n\n\n\nSentence:\n\n+up_first_sunday: The oldest markers in the database go back to the late 1700s\n\n\n+two_way_atc: We found markers going all the way back to the late 1700s.\n\nall_valid_markers_df  %&gt;% \n  arrange(year_erected) %&gt;% \n  select(marker_id, year_erected, url, title, text)  %&gt;% \n  slice(1:10) %&gt;% \n  cat_table(\"Oldest Markers\")\n\n\n\n\nOldest Markers\n\n\n\n\n\n\n\n\n\n\nSentence:\n\n+up_first_sunday: But really markers began to take hold in the early part of the 20th century.\n\n\n+digital: While some markers date back centuries, they proliferated in the 20th century,\n\n\n+two_way_atc: But really you start to see markers take hold in this country in the 1900s, especially when Americans began to hit the open road in their new cars.\n\nall_valid_markers_df %&gt;% \n  summarize(n = n(), .by = year_erected)  %&gt;% \n  arrange(year_erected) %&gt;%\n  ggplot(aes(x = year_erected, y = n))+\n    geom_bar(stat = \"identity\")+\n    labs(title = \"Markers Erected By Year\")\n\n\n\n\n\n\n\n\n\n\n\nOverview\n\n# Organization Completeness Summary ---\n\ndf_summary_org = all_valid_markers_df  %&gt;% \n  mutate(is_org_na = case_when(\n    organization == \"\" ~ \"org_na\",\n    TRUE ~ \"org_complete\"\n  )) %&gt;%\n  group_by(is_org_na) %&gt;%\n  summarise(n = n()) %&gt;%\n  mutate(pct = (n / sum(n))*100)\n\npct_org_complete = df_summary_org[df_summary_org$is_org_na == \"org_complete\", \"pct\"][[1]]\n\n# Year Erected Completeness Summary\n\ndf_summary_year_erected = all_valid_markers_df  %&gt;% \n  mutate(is_year_erected_na = case_when(\n    is.na(year_erected) ~ \"year_erected_na\",\n    TRUE ~ \"year_erected_complete\"\n  )) %&gt;%\n  group_by(is_year_erected_na) %&gt;%\n  summarise(n = n()) %&gt;%\n  mutate(pct = (n / sum(n))*100)\n\npct_year_erected_complete =df_summary_year_erected[df_summary_year_erected$is_year_erected_na == \"year_erected_complete\", \"pct\"][[1]]\n\n# Reported missing\n\ndf_reported_missing = all_valid_markers_df  %&gt;% \n  group_by(is_missing) %&gt;%\n  summarise(n = n()) %&gt;%\n  mutate(pct = (n / sum(n))*100)\n\nMain Marker Table\n\nThe HMDB database has 193,676 markers as of 2024-03-22 when we were sent a copy of the database.\n71.74% of markers have an organization listed.\n45.69% of markers have a year erected listed.\n2.43% of markers have been reported missing.\n\nCategories\n\ndf_markers_without_category = anti_join(all_valid_markers_df, marker_categories_df, by = \"marker_id\") %&gt;% \n  select(marker_id, title, organization, year_erected, marker_no, url)\n\n\n7 markers do not have a category listed. This means that the majority of markers have been categorized which will be helpful for analysis.\n\nThe categories are:\n\ndf_unique_categories =\n  marker_categories_df  %&gt;% \n    distinct(category)\n\n\ncat_table(df_unique_categories, \"Categories\")\n\n\n\n\nCategories\n\n\n\n\n\n\n\n\nSeries\n\ndf_markers_without_series = anti_join(all_valid_markers_df, marker_series_df, by = \"marker_id\") %&gt;% \n  select(marker_id, title, organization, year_erected, marker_no, url)\n\n\n65% of markers are not part of a series.\n\nThe series are:\n\ndf_unique_series = \n  marker_series_df %&gt;% \n  distinct(name, optional_title)\n\n\ncat_table(df_unique_series, \"Series\")\n\n\n\n\nSeries",
    "crumbs": [
      "Analysis",
      "Overview"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Intro",
    "section": "",
    "text": "This notebook covers the data cleaning and analysis for the NPR series “Off The Mark”.\nData comes from the Historical Marker Database was launched by J.J. Prats in 2006. It includes over 180,000 active markers in the United States, contributed by thousands of hobbyists. Anyone who sees a marker can take a photo and submit it to the website. Entries are reviewed by editors to make sure that the marker is permanent, is located outdoors and has information beyond just names, dates and titles.\nUse the sidebar to navigate the code notebook.\nStories that the data analysis appeared in are below:\n\n+digital\n+up_first_sunday\n+marking_hate_watc_radio\n+marking_the_frontier_radio\n+marking_a_murder_radio",
    "crumbs": [
      "Intro",
      "Intro"
    ]
  },
  {
    "objectID": "etl/process-hmdb.html",
    "href": "etl/process-hmdb.html",
    "title": "Process HMDB Data",
    "section": "",
    "text": "This data set is the main markers data set from the Historical Markers Database (HMBD). It was created by running the following query from the SQL database that HMDB provided us. This query was given to us by the maintainer of the data set and returns all valid markers.",
    "crumbs": [
      "ETL (Extract Transform Load)",
      "Process HMDB Data"
    ]
  },
  {
    "objectID": "etl/process-hmdb.html#database-tables",
    "href": "etl/process-hmdb.html#database-tables",
    "title": "Process HMDB Data",
    "section": "Database Tables",
    "text": "Database Tables\nOther tables in the database also contain information about the markers. The tables used so far in our analysis are marked in the below list:\n\nMarkers (This is the primary table. It is used to create a marker page. All other tables support this table.)\nPhotos (This table enumerates and describes all photos in the database.)\nLinks (This table lists and describes links that are pertinent to the marker)\nComments (This table contains commentary related to each marker.)\nRelated Markers (This table lists MarkerIDs that are related to a particular marker. Not all markers have related markers.)\nCategory List (This table lists CategoryIDs of topics that are pertinent to a particular marker.)\nCategories (This table lists the topics, formerly known as categories.)\nSeries List (This table lists the topics, formerly known as categories.)\nSeries (This table names and describes the Series.)\nMarkerOfTheWeek (This table holds Marker of the Week articles.)\nCountiesAndAdjacent (This table holds additional information for each county or equivalent, and its adjacent counties)\nStates (This table holds additional information for each state or province.)\nCountries (This table holds additional information for each country.)\n\nTo see the full detailed explanation of the tables see the HMDB Schema.",
    "crumbs": [
      "ETL (Extract Transform Load)",
      "Process HMDB Data"
    ]
  },
  {
    "objectID": "etl/process-hmdb.html#set-up-r-libraries",
    "href": "etl/process-hmdb.html#set-up-r-libraries",
    "title": "Process HMDB Data",
    "section": "Set up R Libraries",
    "text": "Set up R Libraries\n\nlibrary(tidyverse) # data manipulation\nlibrary(jsonlite) # json manipulation\nlibrary(lubridate) # date manipulation\nlibrary(odbc)\nlibrary(DBI) \nlibrary(here) # path management\nlibrary(glue)\n\n\nclean_data_frame = function(df){\n  \n  df_clean = df %&gt;% \n    janitor::clean_names() %&gt;% # clean column names\n    mutate( \n           across(where(is.character), str_squish)) # clean \n  \n    return(df_clean)\n  \n}\n\n\nremove_html = function(df, column_name){\n\n  df_clean = df  %&gt;% \n    mutate({{column_name}} := str_replace_all({{column_name}}, \"&lt;[^&gt;]*&gt;\", \"\")) %&gt;% \n    mutate({{column_name}} := str_replace_all({{column_name}}, \"\\\"\", \"'\")) %&gt;% \n    mutate({{column_name}} := str_replace_all({{column_name}}, \"\\\"\", \"'\"))\n\n  return(df_clean)\n\n}",
    "crumbs": [
      "ETL (Extract Transform Load)",
      "Process HMDB Data"
    ]
  },
  {
    "objectID": "etl/process-hmdb.html#sql-server",
    "href": "etl/process-hmdb.html#sql-server",
    "title": "Process HMDB Data",
    "section": "SQL Server",
    "text": "SQL Server\nI have a docker container running Microsoft Server on Port 1433.\nThis bash command downloads the sql driver needed to connect to the sql database.\n```{bash}\n/bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install.sh)\"\nbrew tap microsoft/mssql-release https://github.com/Microsoft/homebrew-mssql-release\nbrew update\nHOMEBREW_ACCEPT_EULA=Y brew install msodbcsql18 mssql-tools18\n\n```\nIn the .Renviron make sure to put the folder where the driver is located:\n```{bash}\n\nODBCSYSINI='/opt/homebrew/etc'\n\n```\n\nConnect to the database\n\nconn &lt;- dbConnect(odbc::odbc(),\n                      driver = \"ODBC Driver 18 for SQL Server\",\n                      server = \"localhost\",\n                      database = \"HMdbNPR\",\n                      UID = \"sa\",\n                      PWD = \"reallyStrongPwd123\",\n                      port = 1433,\n                      TrustServerCertificate = \"Yes\"\n)\n\n\n# dbListTables(conn)\n\n\n\nQuery the data from the appropiate tables\n\nall_valid_markers_raw_df = dbGetQuery(conn, '\nSelect * From Markers WHERE Accepted is not Null AND Rejected is Null AND Withdrawn is Null AND ReplacedByID is Null\n')\n\n\n\nrelated_markers_raw_df = dbGetQuery(conn, '\nSelect * From RelatedMarkers\n')\n\ncategory_list_raw_df = dbGetQuery(conn, '\nSelect * From CategoryList\n')\n\ncategories_raw_df = dbGetQuery(conn, '\nSelect * From Categories\n')\n\nseries_list_raw_df = dbGetQuery(conn, '\nSelect * From SeriesList WHERE Accepted is not Null and Rejected is Null and Withdrawn is Null\n')\n\nseries_raw_df = dbGetQuery(conn, '\nSelect * From Series WHERE Accepted is not Null and Rejected is Null and Withdrawn is Null\n')\n\n\ndbDisconnect(conn)\n\n\n\nClean the data for each table\nMake a clean data frame for\n\nall the valid markers\nthe valid markers that are still up (some were taken down or replaced).\n\nFor the markers that are still up, I filtered for: - reported missing is NA & reported_missing_flag is FALSE & confirmed_missingis NA, and confirmed_replaced is NA\n```{r}\n\n filter(is.na(reported_missing) & reported_missing_flag == FALSE & is.na(confirmed_missing) & is.na(confirmed_replaced)) \n\n```\n\n# Filter for US markers and clean \nall_valid_markers_df = all_valid_markers_raw_df %&gt;% \n  clean_data_frame() %&gt;% # Remove extra spaces\n  mutate(X_text_original = text,\n         X_organization_original = organization)  %&gt;% \n  # Clean up original text to remove html\n  remove_html(X_text_original)  %&gt;% \n  remove_html(title) %&gt;% \n  mutate(marker_content = glue(\"title: {title}; text: {X_text_original}\"))  %&gt;% \n  mutate(across(where(is.character) & !all_of(c(\"X_text_original\",\"X_organization_original\")), tolower)) %&gt;% \n  filter(country == \"united states of america\") %&gt;%\n  mutate(across(where(is.character), ~replace(., . == \"null\", NA)))  %&gt;% # replace null with NA\n  relocate(text, .after = title) %&gt;% \n  relocate(organization, .after = title) %&gt;% \n  relocate(marker_no, .after = title) %&gt;% \n  mutate(url = paste0(\"https://www.hmdb.org/m.asp?m=\",marker_id), .before = title)  %&gt;%  # create url column for easy access to marker page  \n  mutate(year_erected = as.numeric(year_erected))  %&gt;%  # convert year erected to numeric\n  mutate(reported_missing_flag = case_when(\n    is.na(reported_missing) ~ FALSE,\n    TRUE ~ TRUE\n  )) %&gt;% \n  mutate(is_missing = case_when(\n\n    !(is.na(reported_missing) & reported_missing_flag == FALSE & is.na(confirmed_missing) & is.na(confirmed_replaced)) ~ TRUE, \n    TRUE ~ FALSE\n\n  ))\n\nall_valid_markers_up_df = all_valid_markers_df %&gt;% \n  filter(is_missing == FALSE)\n\nMake a categories and series data frame that combines the labels with the identifiers.\n\n# Categories\n# ==========\n\n# Marker ID with the category ID\ncategory_list_df &lt;- category_list_raw_df %&gt;% \n  clean_data_frame() %&gt;% \n  mutate(across(where(is.character), tolower))\n\n# Category ID with the category label\ncategories_df &lt;- categories_raw_df %&gt;% \n  clean_data_frame()  %&gt;% \n  mutate(across(where(is.character), tolower))\n\n# Marker ID with the category label\nmarker_categories_df  = left_join(category_list_df, categories_df, by = \"category_id\") %&gt;% \n  select(marker_id, category_id, category)\n\n\n\n# Series \n# =======\n\nseries_list_df = series_list_raw_df %&gt;% \n  clean_data_frame()  %&gt;% \n  mutate(across(where(is.character), tolower))\n\nseries_df = series_raw_df  %&gt;% \n  clean_data_frame()  %&gt;% \n  mutate(across(where(is.character), tolower))\n\nmarker_series_df = left_join(series_list_df, series_df, by = \"series_id\") %&gt;% \n  select(marker_id, series_id, name, optional_title, comments)\n\n\n# Related markers \n# ===============\n\nrelated_markers_df = related_markers_raw_df %&gt;% \n  clean_data_frame()  %&gt;% \n  mutate(across(where(is.character), tolower))\n\n\n\nExport the dataframes to csv\n\nlist_of_dfs &lt;- list(\"all_valid_markers_df\"=all_valid_markers_df, \n                    \"all_valid_markers_up_df\" = all_valid_markers_up_df,\n                    \"marker_categories_df\"= marker_categories_df,\n                    \"marker_series_df\"=marker_series_df)\n\niwalk(list_of_dfs, ~write.csv(.x, here(\"data/processed/hmdb-cleaned/\",glue(\"{.y}.csv\"))))",
    "crumbs": [
      "ETL (Extract Transform Load)",
      "Process HMDB Data"
    ]
  },
  {
    "objectID": "analysis/custom-functions.html",
    "href": "analysis/custom-functions.html",
    "title": "Custom Functions",
    "section": "",
    "text": "library(here)\n\nHere is the .R script that is loaded for each notebook that includes custom functions commonly used.\n\n\n\nlibrary(gt)\n\n# Clean markers data\n# ===================\n\n# All valid markers (ones that were put up and taken down)\nall_valid_markers_df = read.csv(here(\"data/processed/hmdb-cleaned/all_valid_markers_df.csv\")) \n\nall_valid_markers_up_df = read.csv(here(\"data/processed/hmdb-cleaned/all_valid_markers_up_df.csv\"))\n\nmarker_categories_df = read.csv(here(\"data/processed/hmdb-cleaned/marker_categories_df.csv\"))\n\nmarker_series_df = read.csv(here(\"data/processed/hmdb-cleaned/marker_series_df.csv\"))\n\n# Visualization for notebook\n# ==========================\n\ncat_table &lt;- function(df, title, subtitle = NA){\n\n  if(is.na(subtitle)){\n    subtitle = \"\"\n  }\n\n  df  %&gt;% \n    gt() %&gt;% \n    tab_header(\n    title = md(title),\n    subtitle = subtitle\n  ) %&gt;% \n    opt_interactive(use_text_wrapping = FALSE)\n}\n\n\n\nget_marker_category_subset = function(category_str, x_all_markers_df, y_categories_df){\n\n    category_query_df = y_categories_df  %&gt;% \n        filter(category == category_str)\n\n    marker_query_df = x_all_markers_df  %&gt;% \n        filter(marker_id %in% category_query_df$marker_id) %&gt;% \n        mutate(across(where(is.character), ~htmlEscape(., FALSE))) %&gt;% \n        mutate(across(where(is.character), str_squish))  %&gt;% \n        mutate(marker_id = as.character(marker_id))\n\n    return(marker_query_df)   \n\n\n}\n\nget_marker_series_subset = function(category_str, x_all_markers_df, y_series_df){\n\n    series_query_df = y_series_df  %&gt;% \n        filter(name == category_str)\n\n    marker_query_df = x_all_markers_df  %&gt;% \n        filter(marker_id %in% series_query_df$marker_id) %&gt;% \n        mutate(across(where(is.character), ~htmlEscape(., FALSE))) %&gt;% \n        mutate(across(where(is.character), str_squish))  %&gt;% \n        mutate(marker_id = as.character(marker_id))\n\n    return(marker_query_df)   \n\n\n}\n\n\n\n\n\nunnest_all &lt;- function(df) {\n\nnested_cols &lt;- purrr::keep(df, is.list) # Find all nested columns\n\nif (length(nested_cols) &gt; 0) {\n\n# Unnest the first nested column\n\nunnested_df &lt;- df %&gt;%\n\nunnest_wider(col = all_of(names(nested_cols)[1]), names_sep = \"__\")\n\n# Recursively unnest the remaining nested columns\n\nunnest_all(unnested_df)\n\n} else {\n\nreturn(df) # Return the unnested data frame\n\n}\n\n}\n\n\n\n# Convert each row of the DataFrame to a JSON object and save it to a jsonl file\n# Function to convert each row of the DataFrame to a JSON object and save it to a jsonl file\n# Function to stream a DataFrame to a JSON Lines file\nwrite_jsonl_stream &lt;- function(df, filename) {\n  # Open a connection to the file\n  con &lt;- file(filename, \"w\")\n  \n  # Stream out the data\n  stream_out(df, con, pagesize = nrow(df))\n  \n  # Close the connection\n  close(con)\n}\n\n\n# Function to find matching groups for an organization\nfind_matching_groups &lt;- function(organization_name) {\n  matching_groups &lt;- c()\n  \n  # Loop through the named list\n  for (category_name in names(heritage_groups)) {\n    groups &lt;- heritage_groups[[category_name]]$group\n    # print(category_name)\n    # print(\"-------\")\n    # Loop through the groups in the category\n    for (group_info in groups) {\n      group_name &lt;- group_info$name\n     \n      if(is.null(group_info$alt)){\n        vec_names = c(group_name)\n\n      } else {\n        vec_names = c(group_name, group_info$alt)\n      }\n      \n     \n      # Check if the organization_name matches either the name or alt\n      if (str_detect(organization_name, paste(\"\\\\b\", vec_names, \"\\\\b\", sep = \"\", collapse = \"|\"))) {\n        matching_groups &lt;- c(matching_groups, group_name)\n      }\n    }\n  }\n  \n  # Return a comma-separated string of matching group names\n  if (length(matching_groups) &gt; 0) {\n    return(paste(matching_groups, collapse = \", \"))\n  } else {\n    return(NA)\n  }\n}\n\n\n# Southern states\n# https://www2.census.gov/geo/pdfs/maps-data/maps/reference/us_regdiv.pdf\nsouthern_states = c(\n  \"texas\",\n  \"oklahoma\",\n  \"arkansas\",\n  \"louisiana\",\n  \"mississippi\",\n  \"alabama\",\n  \"tennessee\",\n  \"kentucky\",\n  \"florida\",\n  \"georgia\",\n  \"south carolina\",\n  \"north carolina\",\n  \"virginia\",\n  \"west virginia\",\n  \"maryland\",\n  \"delaware\",\n  \"district of columbia\"\n)",
    "crumbs": [
      "Analysis",
      "Custom Functions"
    ]
  },
  {
    "objectID": "analysis/civil-war-markers.html",
    "href": "analysis/civil-war-markers.html",
    "title": "Civil War Markers",
    "section": "",
    "text": "library(tidyverse)\nlibrary(here)\nlibrary(htmltools)\nlibrary(purrr)\nlibrary(gt)\nlibrary(jsonlite)\nlibrary(configr)\nlibrary(RcppTOML)\nlibrary(tictoc)\nlibrary(janitor)\nlibrary(glue)\n\nlibrary(tidycensus)\nsource(here(\"analysis/_functions.R\"))\nI used the category list from the marker database to return all markers tagged as a civil war marker. I created two data frames, one for all civil war markers that had been erected, and one data frame that was for all civil war markers that were marked as currently being up.\n# All civil war markers\ncivil_war_df = get_marker_category_subset(\"war, us civil\",  all_valid_markers_df, marker_categories_df) \n\n# All civil war markers that are up\ncivil_war_up_df = get_marker_category_subset(\"war, us civil\",  all_valid_markers_up_df, marker_categories_df)",
    "crumbs": [
      "Analysis",
      "Civil War Markers"
    ]
  },
  {
    "objectID": "analysis/civil-war-markers.html#heritage-groups",
    "href": "analysis/civil-war-markers.html#heritage-groups",
    "title": "Civil War Markers",
    "section": "Heritage Groups",
    "text": "Heritage Groups\nThis was the method to identify union/federal heritage groups and southern heritage groups and see how many markers they had put up.\nAll marker groups and their alternative names are put into an orgs.toml file.\n\nThe first step is to look at markers that have a civil war topic and fraternal/sorority tags.\n\n\nfraternal_sororal_orgs = get_marker_category_subset(\"fraternal or sororal organizations\",  all_valid_markers_df, marker_categories_df)\n\ncivil_war_frat_sor_df = semi_join(civil_war_df, fraternal_sororal_orgs, join_by(marker_id))\n\n\ncivil_war_frat_sor_df  %&gt;% \n    summarize(n = n(), .by = organization)  %&gt;% \n    cat_table(\"Fraternal and sororal groups in HMDB\")\n\n\n\n\nFraternal and sororal groups in HMDB\n\n\n\n\n\n\n\n\nNext, we look for groups that have confederate or union/federal in their title and group by organizations:\n\n\ncivil_war_df  %&gt;% \n    filter(str_detect(title, \"confed\")) %&gt;% \n    summarize(n = n(), , urls = paste(url, collapse = \", \"),  .by = organization) %&gt;% \n    arrange(desc(n)) %&gt;% cat_table(\"Organizations with confederate in their name\")\n\n\n\n\nOrganizations with confederate in their name\n\n\n\n\n\n\ncivil_war_df  %&gt;% \n    filter(str_detect(title, \"union|federal\")) %&gt;% \n    summarize(n = n(), , urls = paste(url, collapse = \", \"),  .by = organization) %&gt;% \n    arrange(desc(n)) %&gt;% cat_table(\"Organizations with union in their name\")\n\n\n\n\nOrganizations with union in their name\n\n\n\n\n\n\n\n\nAnd final we use data from the Southern Poverty Law Center to look for heritage groups.\n\n\nsplc_df = read.csv(here(\"data/source/Whose Heritage SF - Whose Heritage Master.csv\"))  %&gt;% \n    clean_names()\n\nsplc_orgs_df = splc_df  %&gt;% \n    select(sponsors) %&gt;% \n    separate_wider_delim(cols = sponsors, delim = \";\", names_sep = \"_\", too_few = \"align_start\") %&gt;% \n    pivot_longer(cols = everything(), names_to = \"sponsor_number\", values_to = \"sponsor\") %&gt;% \n    select(sponsor) %&gt;% \n    mutate(sponsor = tolower(str_squish(sponsor))) %&gt;% \n    summarize(n = n(), .by = sponsor) %&gt;% \n    arrange(desc(n))\n\nAll of the groups and their common acronyms or alternative names were added to an orgs.toml file.\nHere is that file:\n\n\n# Union groups\n# =========================\n[union]\n\n    [[union.group]]\n        name = \"daughters of union veterans of the civil war\"\n        alt = [\"daughters of union veterans\", \"daughters of the union veterans\", \"duvcw\", \"daughter of union veterans\", \"daughters of the union\"]\n    [[union.group]]\n        name = \"sons of union veterans of the civil war\"\n        alt = [\"sons of the union veterans\", \"sons of union veterans\", \"suvcw\", \"albert galloway camp no 11, sons of veterans\" ]\n    [[union.group]]\n        name = \"union soldiers and sailors memorial commission\"\n\n    [[union.group]]\n        name = \"st boniface union soldiers monument and memorial association\"\n\n    [[union.group]]\n        name = \"grand army of the republic\"\n        alt = [\"union posts [grand army of the republic]\", \"gar\"]\n\n    [[union.group]]\n        name = \"womans relief corps\"\n        alt = [\"womens relief corps\", \"woman relief corp\", \"women relief corp\", \"women relief corps\",\"wrc\"]\n\n    [[union.group]]\n        name = \"ladies of the grand army of the republic\"\n        alt = [\"ladies of the grand army of the republic\", \"ladies of the gar\"]\n\n    [[union.group]]\n        name = \"union soldiers monument association\"\n\n    [[union.group]]\n        name = \"military order of the loyal legion of the united states\"\n        alt = [\"mollus\"]\n\n    [[union.group]]\n        name = \"union army district of fla\"\n\n    [[union.group]]\n        name = \"national society daughters of the union\"\n        alt = [\"nsdu\"]\n\n    [[union.group]]\n        name = \"honorary first defenders\"\n\n    [[union.group]]\n        name = \"union army district of fla\"\n\n    [[union.group]]\n        name = \"union veteran legion\"\n\n    [[union.group]]\n        name = \"camden soldiers monument association\"\n        \n\n# Confederate groups\n# ====================\n\n[confederate]\n\n    [[confederate.group]]\n        name = \"united daughters of the confederacy\"\n        alt = [\"udc\", \"united daughters (and children) of the confederacy\", \n        \"united daughters of the confedereacy\", \"united daughter of the confederacy\", \"daughters of the confederacy\",\n        \"united daughters of the confederacy\", \"united daughters of confederacy\", \"united daughters of confederacy\" ]\n\n    [[confederate.group]]\n        name = \"confederate centennial commission\"\n\n    [[confederate.group]]\n        name = \"sons of confederate veterans\"\n        alt = [\"scv\", \"sons of conferate veterans\"]\n\n    [[condederate.group]]\n        name = \"sons and daughters of confederate veterans\"\n\n    [[confederate.group]]\n        name = \"the society of the order of the southern cross\"\n        alt = [\"osc\", \"order of the southern cross\"]\n\n    [[confederate.group]]\n        name = \"military order of the stars and bars\"\n        alt = [\"mosb\"]\n\n    [[confederate.group]]\n        name = \"re lee confederate\"\n\n    [[confederate.group]]\n        name = \"martha reid silver confederate memorial association\"\n    \n    [[confederate.group]]\n        name = \"confederate memorial association\"\n\n    [[confederate.group]]\n        name = \"old dominion rifles confederate memorial association\"\n\n    [[confederate.group]]\n        name = \"harmanson-west camp confederate volunteers\"\n\n    [[confederate.group]]\n        name = \"united confederate veterans\"\n        alt = [\"ucv\", \"united confederate veteran\"]\n\n    [[confederate.group]]\n        name = \"order of confederate rose\"\n        alt = [\"ocr\", \"order of the confederate rose\"]\n\n    [[confederate.group]]\n        name = \"ladies memorial association\"\n        alt = [\"lca\"]\n\n    [[confederate.group]]\n        name = \"children of the confederacy\"\n\n    [[confederate.group]]\n        name = \"jefferson davis memorial association\"\n\n    [[confederate.group]]\n        name = \"confederate monument association\"\n\n    [[confederate.group]]\n        name = \"confederate veterans association\"\n\n    [[confederate.group]]\n        name = \"confederate memorial literary society\"\n\n    [[confederate.group]]\n        name = \"oconee southern heritage group\"\n\n    [[confederate.group]]\n        name = \"grand consistory of la\"\n\n    [[confederate.group]]\n        name = \"women of oconee county\"\n\n    [[confederate.group]]\n        name = \"women of lexington county\"\n\n    [[confederate.group]]\n        name = \"the women of cumberland county\"\n    \n    [[confederate.group]]\n        name = \"the women of darlington county\"\n\n    [[confederate.group]]\n        name = \"surviving confederate veterans\"\n\n    \n\n    \n\n    \n\n\nHere are the heritage groups found for each category.\n\nheritage_groups &lt;- parseTOML(here(\"analysis/orgs.toml\"), verbose = FALSE, fromFile = TRUE, includize = FALSE)\n\nconfederate_group_names &lt;- heritage_groups$confederate$group %&gt;%\n  map(\"name\")\n\nunion_group_names &lt;- heritage_groups$union$group %&gt;%\n  map(\"name\")\n\n\ncat_table(tibble(confederate_heritage_groups = confederate_group_names ), \"Confederate Heritage Groups\")\n\n\n\n\nConfederate Heritage Groups\n\n\n\n\n\n\n\n\ncat_table(tibble(union_heritage_groups = union_group_names ), \"Union Heritage Groups\")\n\n\n\n\nUnion Heritage Groups\n\n\n\n\n\n\n\nI then search for matches from the toml file in the Civil War matches.\n\ntic()\ncivil_war_heritage_group_markers_df = civil_war_df   %&gt;% \n    # Remove organizations that are NA\n    filter(!is.na(organization)) %&gt;% \n    # Remove any non alpha numeric characters\n    mutate(organization = gsub(\"[^[:alnum:] ]\", \"\", organization)) %&gt;% \n    # Use the custon function to find all heritage groups in the toml file\n    mutate(matched_groups = sapply(organization, find_matching_groups)) %&gt;% \n    select(marker_id, url, organization, matched_groups, year_erected, is_missing) %&gt;% \n    mutate(has_union_group = if_else(str_detect(matched_groups, paste(union_group_names, collapse = \"|\")), TRUE, FALSE),\n          has_confederate_group = if_else(str_detect(matched_groups, paste(confederate_group_names, collapse = \"|\")), TRUE, FALSE)) %&gt;% \n    filter(!is.na(matched_groups))\ntoc()\n\n\n# write.csv(civil_war_heritage_group_markers_df, here(\"data/processed/civil_war_heritage_group_markers_df.csv\"))\n\n\ncivil_war_heritage_group_markers_df = read.csv(here(\"data/processed/civil_war_heritage_group_markers_df.csv\"))\n\n\nSentence:\n\n+up_first_sunday_podcast: We found the daughters helped erect more than 600 historical markers, far surpassing any other Civil War heritage group\n\n\n+digital: We found the daughters helped erect more than 600 historical markers, far surpassing any other Civil War heritage group\n\n\n+marking_hate_watc_radio: We found the daughters helped erect more than 600 historical markers, far surpassing any other Civil War heritage group, providing it a national – and public – canvas to rewrite the history of the Civil War. \nReturn all markers that were erected by the U.D.C.\n\nudc_markers_df = civil_war_heritage_group_markers_df  %&gt;% \n   tidyr::separate_longer_delim(cols = matched_groups, delim = \",\") %&gt;% \n   mutate(matched_groups = str_squish(matched_groups)) %&gt;% \n   summarize(n = n(), .by = matched_groups) %&gt;% \n   arrange(desc(n))\n\nudc_markers_df  %&gt;% \n  cat_table(\"Heritage Group Summary\")\n\n\n\n\nHeritage Group Summary\n\n\n\n\n\n\n\n\n\n\nSentence:\n\n+up_first_sunday_podcast: Nationwide though, we found these and other markers from Confederate heritage groups far outnumber similar markers from Union groups - with more than twice as many. It was similar with Confederate hospitals and Confederate cemeteries.\n\n\n+digital: Nationwide, markers from Civil War heritage groups like the United Daughters outnumber comparable Union groups’ markers by more than 2-to-1, NPR found. Confederate hospitals and Confederate cemeteries follow a similar pattern.\n\n\n+marking_hate_watc_radio: Nationwide though, we found these and other markers from Confederate heritage groups far outnumber similar markers from Union groups - with more than twice as many. And there were similar patterns for Confederate hospitals and Confederate cemeteries. \n\ncivil_war_heritage_group_markers_df  %&gt;% \n  filter(marker_id %in% civil_war_up_df$marker_id)  %&gt;% \n  summarize(n = n(), .by = c(has_union_group, has_confederate_group)) %&gt;% \n  arrange(desc(n)) %&gt;% \n  cat_table(\"Heritage Groups\")\n\n\n\n\nHeritage Groups\n\n\n\n\n\n\n\nSearch for markers that mention Confederate hospitals but don’t mention union hospitals and vice versa\n\n# Markers that mention Confederate hospitals but don't mention Union hospitals and vice versa\nhospital_type_df = civil_war_up_df %&gt;% \n  mutate(marker_id = as.double(marker_id))  %&gt;% \n  mutate(hospital_type = case_when(\n    (str_detect(title, \"confederate hospital|grey hospital|gray hospital\") | str_detect(text, \"confederate hospital|grey hospital|gray hospital\")  )  & !((str_detect(title, \"union hospital|blue hospital|federal hospital\") | str_detect(text, \"union hospital|blue hospital|federal hospital\"))) ~ \"confederate_hospital\",\n    (str_detect(title, \"union hospital|blue hospital|federal hospital\") | str_detect(text, \"union hospital|blue hospital|federal hospital\")) & !((str_detect(title, \"confederate hospital|grey hospital|gray hospital\") | str_detect(text, \"confederate hospital|grey hospital|gray hospital\"))) ~ \"union_hospital\",\n    TRUE ~ \"NONE\" \n  ))  %&gt;% \n  select(marker_id, url, hospital_type) %&gt;% \n  filter(hospital_type != \"NONE\")\n\nhospital_summary_df = hospital_type_df %&gt;% \n  summarize(n = n(), .by = c(hospital_type))  \n\n\ncat_table(hospital_summary_df, \"Hospital Markers\")\n\n\n\n\nHospital Markers\n\n\n\n\n\n\n\nSearch for markers that mention Confederate cemeteries but don’t mention Union cemeteries and vice versa\n\ncemetery_type_df = civil_war_up_df  %&gt;% \n  mutate(cemetery_type = case_when(\n    (str_detect(title, \"confederate cemetery|grey cemetery|gray cemetery\") | str_detect(text, \"confederate cemetery|grey cemetery|gray cemetery\")  )  & !((str_detect(title, \"union cemetery|blue cemetery|federal cemetery\") | str_detect(text, \"union cemetery|blue cemetery|federal cemetery\"))) ~ \"confederate_cemetery\",\n    (str_detect(title, \"union cemetery|blue cemetery|federal cemetery\") | str_detect(text, \"union cemetery|blue cemetery|federal cemetery\")) & !((str_detect(title, \"confederate cemetery|grey cemetery|gray cemetery\") | str_detect(text, \"confederate cemetery|grey cemetery|gray cemetery\"))) ~ \"union_cemetery\",\n    TRUE ~ \"NONE\" \n  ))  %&gt;% \n  select(marker_id, url, cemetery_type) %&gt;% \n  filter(cemetery_type != \"NONE\")\n\ncemetery_summary_df = cemetery_type_df %&gt;% \n  summarize(n = n(), .by = c(cemetery_type))  \n\ncat_table(cemetery_summary_df, \"Cemetery Markers\")\n\n\n\n\nCemetery Markers\n\n\n\n\n\n\n\n\n\n\nSentence\n\n+up_first_sunday_podcast: Markers to them and the Confederacy are prolific - with more than 12 thousand mentions. But while the war was fought over slaves and slavery, those words show up only about half as many times.\n\n\n+digital: In all, markers about Confederates or the Confederacy are prolific, with more than 12,000 mentions. But despite the war’s root causes, the words slaves and slavery show up only about half as many times.\n\n\n+marking_hate_watc_radio: In all, there are more than 12,000 markers in the database using the word Confederate or Confederacy. Only about a half of that use slave or slavery. \nSearch for markers with the “confed” stem to match words like confederacy and confederate and then add them up.\nThen search for markers with the “slave” stem to match words like enslaved, slave, or slavery.\n\nconfederacy_slavery_df =  all_valid_markers_up_df %&gt;% \n  mutate(mention_confederacy = str_detect(title, \"confed\") | str_detect(text, \"confed\")) %&gt;% \n  mutate(mention_slavery = str_detect(title, \"slave\") | str_detect(text, \"slave\") )  %&gt;% \n  select(marker_id, url, year_erected, mention_slavery, mention_confederacy)\n\nconfederacy_slavery_df  %&gt;% \n  summarize(n = n(), .by = c(mention_confederacy )) %&gt;% \n  cat_table(\"Markers that mention confederacy by name\")\n\n\n\n\nMarkers that mention confederacy by name\n\n\n\n\n\n\nconfederacy_slavery_df  %&gt;% \n  summarize(n = n(), .by = c(mention_slavery )) %&gt;% \n  cat_table(\"Markers that mention slavery\")\n\n\n\n\nMarkers that mention slavery\n\n\n\n\n\n\n\n\n\n\nSentence\n\n+up_first_sunday_podcast: While other groups have spent the past 20 years taking Confederate symbols down, the United Daughters put 47 more markers up\n\n\n+digital: While many communities have begun taking Confederate symbols down, the United Daughters have put up 47 more markers over the last two decades.\n\n\n+marking_hate_watc_radio: While other groups have spent the past 20 years taking Confederate symbols down, the United Daughters put 47 more markers up\n\nudc_past_20_years = civil_war_heritage_group_markers_df  %&gt;% \n  filter(str_detect(matched_groups, \"united daughters of the confederacy\" )) %&gt;% \n  filter(year_erected &gt; 2003)\n\nudc_past_20_years  %&gt;% cat_table(\"Past 20 Years UDC\")\n\n\n\n\nPast 20 Years UDC\n\n\n\n\n\n\n\n\n\n\nSentence:\n\n+digital: Across the South, markers honor notable men and notable houses without mentioning the forced, free labor that made both the homes and the men’s wealth possible.\n\n\n+marking_hate_watc_radio: More than 500 markers honor notable men and notable houses without mentioning the forced free labor that made both possible.\nDownloaded the data from Washington Post’s slaveholding members of congress.\n\nFiltered for those who were slave owners\nFor each state, took all of the members of Congress and searched for their names in the marker database, looking only at markers that are from the same state as the person.\nThen search for the words congressman, representative, or senator to make sure it was about a member of Congress.\nThen search for the stem “slave”\n\n\ndf_congress_slave_raw = read_csv(here(\"data\", \"source\", \"wapo\", \"congress_slaveowners.csv\")) \n\ndf_congress_slave = df_congress_slave_raw  %&gt;% \n  mutate(name_clean = str_squish(tolower(name))) %&gt;% \n  filter(is_slaveholder == \"true\")\n\n\nsearch_names = df_congress_slave$name_clean\n\ndf_state_list &lt;- fips_codes %&gt;%\n  distinct(state, state_name) %&gt;% \n  mutate(across(everything(), tolower))\n\ntic()\n\nstate_name_list = df_congress_slave  %&gt;% \n  select(name, states_served) %&gt;% \n  mutate(states_list = str_split(states_served, ',')) %&gt;% \n  unnest(states_list) %&gt;% \n  select(name, states_list)  %&gt;% \n  mutate(name = str_squish(tolower(name))) %&gt;% \n  summarise(names = list(name), .by = states_list) %&gt;% \n  mutate(states_list = tolower(states_list)) %&gt;% \n  left_join(df_state_list, join_by(states_list == state))  %&gt;% \n  select(state_name, names)  %&gt;% \n  deframe()\n\n \n\n\ndf_congress_result = tibble()\n\n\nfor (state_name in unique(all_valid_markers_up_df$state)){\n\n  # Filter markers for that state\n\n  data = all_valid_markers_up_df  %&gt;% \n    filter(state == state_name)  %&gt;% \n     mutate(across(where(is.character), ~replace_na(.,\"\")))\n\n  # Filter for search names\n\n   search_names = state_name_list[[state_name]]\n\n   if(length(search_names &gt; 0)){\n\n\n\n\n  # Make Results Matrix\n\n  results &lt;- matrix(FALSE, nrow = nrow(data), ncol = length(search_names))\n\n  # Loop through each search name and use str_detect for both columns\n  for (i in 1:length(search_names)) {\n  \n    search_result = str_detect(data$title, pattern = fixed(search_names[i])) | str_detect(data$text, pattern = fixed(search_names[i]))\n    results[, i] &lt;- search_result\n  }\n\n\n  df_result = tibble()\n  for(i in 1:length(search_names)){\n    \n    df = data[results[,i],]\n    if(nrow(df) &gt; 0){\n\n      col_name = rep(search_names[i], time = length(unique(df$marker_id)))\n      col_state = rep(state_name, time = length(unique(df$marker_id)))\n      df_temp = tibble(name = col_name, marker_id =  df$marker_id, state = col_state)\n      df_result = bind_rows(df_result, df_temp)\n    } else {\n\n      next\n    }\n    \n  }\n\n  df_congress_result = bind_rows(df_congress_result, df_result)\n\n  #print(df_congress_result)\n\n  #print(glue(\"{state_name} done ------------------\"))\n\n   } else{\n    #print(glue(\"{state_name} done\"))\n\n    next\n   }\n\n  \n\n\n\n}\n\ntoc()\n\n23.272 sec elapsed\n\n\n\ndf_markers_to_congress_slave_owners =  all_valid_markers_up_df %&gt;% \n  filter(marker_id %in% df_congress_result$marker_id) %&gt;% \n  select(marker_id, url, title, text, year_erected, organization, state, town) %&gt;% \n  left_join(df_congress_result, join_by(marker_id)) %&gt;% \n  relocate(name, .after = marker_id) %&gt;% \n  filter(str_detect(text, \"congressman|representative|senator\")) %&gt;% \n  distinct(marker_id, .keep_all = TRUE) %&gt;% \n  mutate(mention_slavery = str_detect(text, \"slave\"))  %&gt;% \n  mutate(is_in_south = if_else(state.x %in% southern_states, TRUE, FALSE))\n\n\ndf_markers_to_congress_slave_owners   %&gt;% \n  summarize(n = n(), .by = mention_slavery) %&gt;% \n  cat_table(\"Congressmen markers that don't mention slaves\")\n\n\n\n\nCongressmen markers that don’t mention slaves\n\n\n\n\n\n\n\n\n\n\nSentence\n\n+digital: NPR’s analysis revealed more than 500 markers that describe the Confederacy in glowing terms, vilify the Union, falsify the reasons for the war or recast Confederate soldiers as the war’s true heroes.\n\n\n+two_way_atc: There are more than 500 markers in this country that glorify the confederacy, vilify the union, or falsify the reasons for the war.\n\nsouthern_names_civil_war = c(\"war between the states\")\nconfederate_states = c(\"texas\", \"arkansas\", \"louisiana\", \"tennessee\", \"mississippi\", \"alabama\", \"georgia\", \"florida\", \"south carolina\", \"north carolina\", \"virginia\")\n\nwar_between_states_df = all_valid_markers_up_df  %&gt;% \n  mutate(war_between_states = case_when(\n\n    str_detect(text,paste(southern_names_civil_war, collapse = \"|\") ) | str_detect(title, paste(southern_names_civil_war, collapse = \"|\") ) | str_detect(subtitle, paste(southern_names_civil_war, collapse = \"|\") ) |  str_detect(subtitle2,paste(southern_names_civil_war, collapse = \"|\") ) ~ TRUE,\n\n    TRUE ~ FALSE))  %&gt;% \n    filter(war_between_states == TRUE) %&gt;% \n    filter(state %in% confederate_states ) %&gt;% \n    select(marker_id, url, war_between_states)\n\nSelect markers that have signs of glowing terms toward the Confederacy, vilify the Union, falsify the reasons for the war, or recast Confederate soldiers as heroes.\n\n# Language patterns\nconfederate_patterns = c(\"served in the confederacy\",\"\\\\bcsa\\\\b\",\"\\\\bc.s.a\\\\b\",\"\\\\bconfederate hero\\\\b\",\"\\\\bsaved the south\\\\b\",\"confederate units\",\"gallant confederate\",\"gallent confederate\",\"brave confederate\",\"served in the confederacy\",\"to the confederate soldiers\",\"southern heroism\",\"stunning confederate victory\",\"confederate states of america\",\"confederate infantry regiment\",\"confederate soliders of\" , \"honor the confederate soldiers\", \"valor of the confederate soldiers\")\n\n# Heritage Groups\nheritage_confed_df = civil_war_heritage_group_markers_df  %&gt;% \n  filter(has_confederate_group == TRUE & has_union_group == FALSE)\n\n# Names for civil war common in the south\n\nall_southern_civil_war_names = c(\"war between the states\", \"the war for southern independence\", \"war against northern aggression\", \"war of northern aggression\", \"second american revolution\")\n\nwar_confed_name_df =  all_valid_markers_up_df  %&gt;% \n  mutate(southern_name= case_when(\n\n    str_detect(text,paste(all_southern_civil_war_names , collapse = \"|\") ) | str_detect(title, paste(all_southern_civil_war_names , collapse = \"|\") ) | str_detect(subtitle, paste(all_southern_civil_war_names , collapse = \"|\") ) |  str_detect(subtitle2,paste(all_southern_civil_war_names , collapse = \"|\") ) ~ TRUE,\n\n    TRUE ~ FALSE)) %&gt;% \n  filter(southern_name == TRUE)\n\n\nglowing_to_confederacy_to_check = civil_war_up_df  %&gt;% \n  # clean up html\n  mutate(text = str_replace_all(text, \"&lt;|br&gt;|&lt;|center&gt;|/b&gt;|b&gt;\", \"\"))%&gt;%\n  mutate(text = str_remove_all(text, \"&lt;[^&gt;]+&gt;\"))  %&gt;% \n  mutate(text = str_squish(text)) %&gt;% \n  # Some patterns of markers that glowingly describe the Confederacy\n  mutate(matched_confed_pattern_text = sapply(str_extract_all(text, paste(confederate_patterns, collapse = \"|\")), paste, collapse = \", \"), .before = url) %&gt;% \n  mutate(has_confed_pattern = if_else(matched_confed_pattern_text == \"\", FALSE, TRUE))  %&gt;% \n  mutate(from_confed_heritage = if_else(marker_id %in% heritage_confed_df$marker_id, TRUE, FALSE)) %&gt;% \n  mutate(civil_war_confed_name = if_else(marker_id %in% war_confed_name_df$marker_id, TRUE, FALSE)) %&gt;% \n  mutate(confed_in_title = if_else(str_detect(title, \"confed\"), TRUE, FALSE))  %&gt;% \n  mutate(ranking = has_confed_pattern + from_confed_heritage + civil_war_confed_name + confed_in_title) %&gt;% \n  select(url, marker_id, ranking, title, has_confed_pattern, from_confed_heritage, civil_war_confed_name, confed_in_title, text ) %&gt;% \n  filter(ranking != 0) %&gt;% \n  arrange(desc(ranking)) %&gt;% \n  mutate(glowing = \"\", .after = url)\n  # filter(matched_confed_pattern_text != \"\")\n\nwrite_csv(glowing_to_confederacy_to_check , here(\"data/processed/glowing_to_confederacy_to_check.csv\"))\n\nAfter checking them by hand markers that were either glowing to the confederacy, vilified the union, or recast the confederate soldiers as heroes (marked true in the glowing category) the markers are read back in and filtered for true. These markers are then combined with all markers from states that were in the Confederacy that refer to the civil war as the “War Between States”, which falsifies the reasons for the war.\n\ncheck_glowing_terms_df = read_csv(here(\"data/handmade/checked_glowing_confederacy.csv\"))\n\nglowing_falsify_df = check_glowing_terms_df  %&gt;% \n  filter(glowing == \"1\") %&gt;% \n  select(marker_id, glowing) %&gt;% \n  full_join(war_between_states_df, join_by(marker_id)) %&gt;% \n  distinct(marker_id, .keep_all = TRUE)\n\n\nnrow(glowing_falsify_df)\n\n[1] 843",
    "crumbs": [
      "Analysis",
      "Civil War Markers"
    ]
  }
]